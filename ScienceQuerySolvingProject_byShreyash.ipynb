{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HX-MZsqByt4"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install Necessary Packages (Latest Stable Versions)\n",
        "# Upgrading pip first and installing latest crewai/langchain versions.\n",
        "# This aims for compatibility with the Colab environment.\n",
        "\n",
        "!pip install --upgrade pip -q\n",
        "!pip install -q crewai crewai[tools] langchain-google-genai python-dotenv google-api-python-client langchain-community\n",
        "\n",
        "print(\"--- Packages Installed (Latest Stable Versions) ---\")\n",
        "# It's ESSENTIAL to restart the Colab Runtime after installing/changing package versions.\n",
        "# This ensures the newly installed libraries are loaded correctly.\n",
        "print(\"--- !!! IMPORTANT: Please RESTART the Colab Runtime now (Runtime -> Restart Session) !!! ---\")\n",
        "print(\"--- After restarting, re-run all cells starting from Cell 2. ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: API Key Configuration (Using Direct Input - Option 2)\n",
        "# Securely store and load your API keys for Gemini and Serper.\n",
        "# RUN THIS CELL AFTER RESTARTING THE RUNTIME\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"--- Configuring API Keys using Direct Input (Option 2) ---\")\n",
        "\n",
        "# --- OPTION 1: Using Colab Secrets (Recommended for better security) ---\n",
        "# To use this: comment out Option 2, uncomment these lines, and add\n",
        "# 'GEMINI_API_KEY', 'SERPER_API_KEY' to Colab Secrets (key icon).\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "# os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY')\n",
        "\n",
        "# --- OPTION 2: Paste keys directly (Less Secure - Use with caution) ---\n",
        "print(\"Setting keys directly using Option 2...\")\n",
        "# >>> ACTION REQUIRED: Uncomment the two lines below and replace placeholders <<<\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"YOUR_GEMINI_API_KEY\"  # PASTE YOUR ACTUAL GEMINI KEY HERE\n",
        "os.environ[\"SERPER_API_KEY\"] = \"YOUR_SERPER_API_KEY\"  # PASTE YOUR ACTUAL SERPER KEY HERE\n",
        "\n",
        "\n",
        "# --- Verification ---\n",
        "# Checks if the keys seem to be loaded (not foolproof, but catches placeholders).\n",
        "gemini_key_check = os.environ.get(\"GEMINI_API_KEY\")\n",
        "serper_key_check = os.environ.get(\"SERPER_API_KEY\")\n",
        "\n",
        "# Basic validation\n",
        "if not gemini_key_check or gemini_key_check == \"YOUR_GEMINI_API_KEY\":\n",
        "    print(\"⚠️ ERROR: Gemini API Key not found or is still the placeholder value.\")\n",
        "    print(\"       Please uncomment the line in Option 2 and paste your key inside the quotes.\")\n",
        "elif not serper_key_check or serper_key_check == \"YOUR_SERPER_API_KEY\":\n",
        "    print(\"⚠️ ERROR: Serper API Key not found or is still the placeholder value.\")\n",
        "    print(\"       Please uncomment the line in Option 2 and paste your key inside the quotes.\")\n",
        "else:\n",
        "    print(\"✅ --- API Keys Seem Loaded via Option 2 (Please ensure they are correct and active) ---\")"
      ],
      "metadata": {
        "id": "r-YQmW_AB_ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Import Necessary Libraries\n",
        "# Imports required modules from CrewAI, LangChain, Google, and standard libraries.\n",
        "# RUN THIS CELL AFTER RESTARTING THE RUNTIME and running Cell 2\n",
        "\n",
        "import warnings\n",
        "import os\n",
        "import traceback # For detailed error reporting\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from crewai_tools import SerperDevTool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI # LangChain wrapper for Gemini\n",
        "\n",
        "print(\"--- Libraries Imported ---\")"
      ],
      "metadata": {
        "id": "5tLRstblCE9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Configure LLM (LangChain Wrapper) and Tools (Force Key Re-Read)\n",
        "# Initializes the core components: the Language Model and the Web Search Tool.\n",
        "# Adds extra checks and explicit key passing to debug persistent API key errors.\n",
        "# RUN THIS CELL AFTER RESTARTING THE RUNTIME and running Cells 2-3\n",
        "\n",
        "import os\n",
        "import traceback\n",
        "import warnings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI # Ensure import is here\n",
        "\n",
        "warnings.filterwarnings('ignore') # Suppress common warnings\n",
        "\n",
        "# Initialize variables\n",
        "llm = None\n",
        "web_scraper_tool = None\n",
        "\n",
        "# --- Configure Language Model (Gemini via LangChain) ---\n",
        "try:\n",
        "    print(\"--- Reading GEMINI_API_KEY from environment *immediately* before LLM setup ---\")\n",
        "    # Force re-read from environment variable set in Cell 2\n",
        "    gemini_api_key_from_env = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "    # Basic validation and Debug Print\n",
        "    if not gemini_api_key_from_env or gemini_api_key_from_env == \"YOUR_NEW_VALID_GEMINI_KEY\" or len(gemini_api_key_from_env) < 10: # Basic length check\n",
        "         print(f\"⚠️ ERROR: GEMINI_API_KEY read from environment appears invalid or placeholder.\")\n",
        "         print(f\"   Value found: {gemini_api_key_from_env}\")\n",
        "         raise ValueError(\"GEMINI_API_KEY environment variable not set correctly or invalid.\")\n",
        "    else:\n",
        "        # Mask most of the key for security in printing\n",
        "        masked_key = gemini_api_key_from_env[:4] + \"****\" + gemini_api_key_from_env[-4:]\n",
        "        print(f\"✅ Key read from environment successfully. Using key: {masked_key}\")\n",
        "\n",
        "    # Specify the desired, VALID Gemini model name\n",
        "    selected_model = 'gemini-1.5-flash'\n",
        "    print(f\"--- Attempting to configure LangChain LLM wrapper with model: {selected_model} ---\")\n",
        "\n",
        "    # Instantiate the LangChain wrapper, explicitly passing the key we just read\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=selected_model,\n",
        "        google_api_key=gemini_api_key_from_env, # Explicitly pass the just-read key\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "    print(f\"--- LangChain LLM Wrapper Configured (Using Gemini model: {selected_model}) ---\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"🚨 Error configuring LangChain ChatGoogleGenerativeAI: {e}\")\n",
        "    print(\"🚨 Please ensure:\")\n",
        "    print(\"   - Your GEMINI_API_KEY in Cell 2 is correct, active, and was read correctly above.\")\n",
        "    print(f\"   - The model name '{selected_model}' is valid for your API key.\")\n",
        "    print(\"   - Billing is enabled in your Google Cloud project if required.\")\n",
        "    print(\"\\n--- LLM Configuration Error Traceback ---\")\n",
        "    traceback.print_exc()\n",
        "    print(\"--- End LLM Configuration Error Traceback ---\")\n",
        "    llm = None # Ensure llm is None if setup failed\n",
        "\n",
        "# --- Configure Web Scraping Tool (Serper) --- (No changes here)\n",
        "try:\n",
        "    serper_api_key = os.environ.get(\"SERPER_API_KEY\")\n",
        "    if not serper_api_key or serper_api_key == \"YOUR_VERIFIED_SERPER_KEY\": raise ValueError(\"SERPER_API_KEY invalid.\")\n",
        "    web_scraper_tool = SerperDevTool()\n",
        "    print(\"--- Web Scraper Tool (Serper) Initialized ---\")\n",
        "except Exception as e:\n",
        "    print(f\"🚨 Error initializing SerperDevTool: {e}\"); traceback.print_exc(); web_scraper_tool = None\n",
        "\n",
        "# --- Final Initialization Check ---\n",
        "if not llm:\n",
        "    print(\"\\n🚨🚨🚨 CRITICAL ERROR: LLM object failed to initialize. Cannot proceed. Review Cell 4 output. 🚨🚨🚨\")\n",
        "elif not web_scraper_tool:\n",
        "     print(\"\\n🚨🚨🚨 CRITICAL ERROR: Web Scraper tool failed to initialize. Cannot proceed. Review Cell 4 output. 🚨🚨🚨\")\n",
        "else:\n",
        "    print(\"--- LLM and Tools Initialization Check Passed ---\")"
      ],
      "metadata": {
        "id": "pjJ8vJZ-CHUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Define the Agents (Explicitly Assigning LLM to Each Agent)\n",
        "# Creates each specialized agent for the Science Department simulation.\n",
        "# The configured LangChain LLM object ('llm') is passed directly to each agent.\n",
        "# RUN THIS CELL AFTER RESTARTING THE RUNTIME and running Cells 2-4\n",
        "\n",
        "# --- Verification ---\n",
        "# Double-check that the LLM and Tool objects from Cell 4 are available.\n",
        "if 'llm' not in globals() or llm is None:\n",
        "   raise NameError(\"LLM object 'llm' was not successfully created in Cell 4. Cannot define agents.\")\n",
        "if 'web_scraper_tool' not in globals() or web_scraper_tool is None:\n",
        "   raise NameError(\"Tool 'web_scraper_tool' was not successfully created in Cell 4. Cannot define agents.\")\n",
        "\n",
        "# --- Agent Definitions ---\n",
        "print(\"--- Defining Agents and assigning the configured LangChain LLM object ('llm') to each ---\")\n",
        "\n",
        "# Agent for handling user input\n",
        "query_intake_agent = Agent(\n",
        "    role='Query Intake and Routing Specialist',\n",
        "    goal='Refine user queries for clarity and specificity, identifying the core scientific question and relevant domain.',\n",
        "    backstory=\"Acts as the gateway to the Science Department simulator. Specializes in interpreting user needs and translating them into precise, actionable prompts for scientific analysis.\",\n",
        "    llm=llm, # Explicitly assign the configured Gemini LLM object\n",
        "    verbose=True,\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "# Agent for formatting the final output\n",
        "output_formatting_agent = Agent(\n",
        "    role='Science Communication Editor',\n",
        "    goal='Transform technical scientific output into a clear, engaging, and well-structured response using Markdown.',\n",
        "    backstory=\"Serves as the final polish stage. Excels at making complex information accessible and presentable, focusing on readability, structure, and appropriate formatting without altering scientific content.\",\n",
        "    llm=llm, # Explicitly assign the configured Gemini LLM object\n",
        "    verbose=True,\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "# Science Agent: Theoretical Physics\n",
        "theoretical_physicist_agent = Agent(\n",
        "    role='Theoretical and Classical Physicist',\n",
        "    goal='Analyze phenomena using foundational physics principles (classical mechanics, thermo, EM, relativity) and develop theoretical models.',\n",
        "    backstory=\"Expert in the macroscopic laws of physics. Provides rigorous analysis based on established theories.\",\n",
        "    llm=llm, # Explicitly assign the configured Gemini LLM object\n",
        "    verbose=True,\n",
        "    allow_delegation=True, # Can delegate to other specialists\n",
        "    tools=[web_scraper_tool] # Access to web search\n",
        ")\n",
        "\n",
        "# Science Agent: Quantum/Nuclear Physics\n",
        "quantum_nuclear_physicist_agent = Agent(\n",
        "    role='Quantum Mechanics and Nuclear Physicist',\n",
        "    goal='Explain phenomena at atomic and subatomic scales using quantum principles (states, particles, reactions).',\n",
        "    backstory=\"Focuses on the quantum realm, including particle interactions, nuclear energy, and wave-particle duality.\",\n",
        "    llm=llm, # Explicitly assign the configured Gemini LLM object\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    tools=[web_scraper_tool]\n",
        ")\n",
        "\n",
        "# Science Agent: Astrophysics/Astronomy\n",
        "astrophysicist_astronomer_agent = Agent(\n",
        "    role='Astrophysicist and Astronomer',\n",
        "    goal='Investigate cosmic objects and phenomena (stars, galaxies, cosmology), applying physics to understand the universe.',\n",
        "    backstory=\"Studies the universe at large scales, from planetary systems to cosmology. Interprets astronomical data.\",\n",
        "    llm=llm, # Explicitly assign the configured Gemini LLM object\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    tools=[web_scraper_tool]\n",
        ")\n",
        "\n",
        "# Science Agent: Electrical Engineering/Instrumentation\n",
        "electrical_instrumentation_agent = Agent(\n",
        "    role='Electrical Engineer and Instrumentation Expert',\n",
        "    goal='Provide expertise on electrical systems (circuits, sensors, controls) and practical instrument design/limitations.',\n",
        "    backstory=\"Bridges theory and practical implementation for electrical and electronic systems. Understands signal processing and sensor technology.\",\n",
        "    llm=llm, # Explicitly assign the configured Gemini LLM object\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    tools=[web_scraper_tool]\n",
        ")\n",
        "\n",
        "# Science Agent: Mathematics/Statistics\n",
        "mathematician_statistician_agent = Agent(\n",
        "    role='Mathematician and Statistician',\n",
        "    goal='Apply mathematical rigor and statistical methods (modeling, analysis, computation) to support scientific inquiry.',\n",
        "    backstory=\"Provides the quantitative foundation for the department. Develops models, analyzes data, assesses uncertainty.\",\n",
        "    llm=llm, # Explicitly assign the configured Gemini LLM object\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    tools=[web_scraper_tool]\n",
        ")\n",
        "\n",
        "# --- Confirmation ---\n",
        "print(\"--- Agents Defined (LLM Explicitly Assigned to Each Agent) ---\")"
      ],
      "metadata": {
        "id": "557X549fCI3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Define the Tasks (Using Context Passing)\n",
        "# Specifies the individual steps the Crew will undertake to fulfill the user's request.\n",
        "# Uses the 'context' parameter to pass results from one task to the next.\n",
        "# RUN THIS CELL AFTER RESTARTING THE RUNTIME and running Cells 2-5\n",
        "\n",
        "# Define the list of potential delegatees for the science task\n",
        "science_agents = [\n",
        "    theoretical_physicist_agent,\n",
        "    quantum_nuclear_physicist_agent,\n",
        "    astrophysicist_astronomer_agent,\n",
        "    electrical_instrumentation_agent,\n",
        "    mathematician_statistician_agent\n",
        "]\n",
        "\n",
        "# Task 1: Refine the user's initial query.\n",
        "intake_task = Task(\n",
        "    description=(\n",
        "        \"1. Receive the user's input topic: '{user_topic}' and prompt: '{user_prompt}'.\\n\"\n",
        "        \"2. Analyze for clarity, feasibility, and the core scientific question.\\n\"\n",
        "        \"3. Rewrite the prompt to be specific, actionable, and clear for analysis.\\n\"\n",
        "        \"4. Identify the most relevant primary scientific field.\\n\"\n",
        "        \"5. **Output ONLY the single refined prompt string**.\"\n",
        "    ),\n",
        "    expected_output=\"A single string containing only the refined, actionable prompt suitable for a science agent.\",\n",
        "    agent=query_intake_agent # Assigns this task to the input agent.\n",
        "    # Output is implicitly passed to tasks that list 'intake_task' in their context.\n",
        ")\n",
        "\n",
        "# Task 2: Perform the core scientific analysis based on the refined prompt.\n",
        "science_analysis_task = Task(\n",
        "    description=(\n",
        "        \"Analyze the refined scientific prompt provided **via context from the intake task**. \"\n",
        "        \"Perform necessary research, calculations, and reasoning based on your assigned role's expertise. \"\n",
        "        \"If the prompt requires knowledge outside your core specialization, you MAY delegate to a more suitable expert from the available team if appropriate for achieving the goal. \"\n",
        "        \"If current information, specific data, or recent findings are needed, use the 'SerperDevTool' web scraping tool. Cite external sources clearly if used. \"\n",
        "        \"Generate a comprehensive, technically accurate, and well-reasoned response.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A detailed, scientifically accurate, and well-reasoned technical response addressing the refined prompt. \"\n",
        "        \"If the web scraping tool was used, citations or clear integration of findings should be present. \"\n",
        "        \"The output should be suitable for final editing.\"\n",
        "    ),\n",
        "    agent=theoretical_physicist_agent, # Assign to a primary science agent (can delegate).\n",
        "    context=[intake_task] # Explicitly states this task needs the output context from 'intake_task'.\n",
        ")\n",
        "\n",
        "# Task 3: Format the technical response for presentation.\n",
        "formatting_task = Task(\n",
        "    description=(\n",
        "        \"Receive the technical scientific response **via context from the analysis task**. Format it for presentation to the end-user.\\n\"\n",
        "        \"Mandatory formatting requirements:\\n\"\n",
        "        \"1. Ensure clarity, coherence, and a professional, informative tone.\\n\"\n",
        "        \"2. Correct minor grammatical errors or awkward phrasing.\\n\"\n",
        "        \"3. Structure the information logically using paragraphs, headings (if appropriate), and lists.\\n\"\n",
        "        \"4. Apply Markdown formatting effectively for emphasis (**bold**), key terms (*italics*), lists (bulleted or numbered), and potentially code blocks for equations or formulas.\\n\"\n",
        "        \"5. Ensure the final output is well-structured, easy to read, and visually appealing.\\n\"\n",
        "        \"6. CRITICAL: Do NOT add new scientific information or opinions; focus solely on presenting the provided technical content effectively.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A polished, well-formatted, and easily understandable version of the scientific response, \"\n",
        "        \"using Markdown extensively and effectively for presentation.\"\n",
        "    ),\n",
        "    agent=output_formatting_agent, # Assigns this task to the output agent.\n",
        "    context=[science_analysis_task] # Explicitly states this task needs the output context from 'science_analysis_task'.\n",
        ")\n",
        "\n",
        "print(\"--- Tasks Defined (Using Context Passing for Dependencies) ---\")"
      ],
      "metadata": {
        "id": "bSSy_JSWCMcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Create and Configure the Crew\n",
        "# Assembles the agents and tasks into a cohesive Crew responsible for execution.\n",
        "# Relies on the LLM assigned individually to each agent in Cell 5.\n",
        "# RUN THIS CELL AFTER RESTARTING THE RUNTIME and running Cells 2-6\n",
        "\n",
        "# --- Verification ---\n",
        "# Ensure the base LLM object exists for potential use elsewhere (like Cell 8 direct test if re-enabled)\n",
        "if 'llm' not in globals() or llm is None:\n",
        "   raise NameError(\"LLM object 'llm' from Cell 4 is needed but wasn't created.\")\n",
        "\n",
        "# --- Crew Assembly ---\n",
        "# Combine all defined agents into a list for the Crew.\n",
        "all_agents = [\n",
        "    query_intake_agent,\n",
        "    theoretical_physicist_agent,\n",
        "    quantum_nuclear_physicist_agent,\n",
        "    astrophysicist_astronomer_agent,\n",
        "    electrical_instrumentation_agent,\n",
        "    mathematician_statistician_agent,\n",
        "    output_formatting_agent\n",
        "]\n",
        "\n",
        "# Define the sequence of tasks for the Crew to execute.\n",
        "crew_tasks = [\n",
        "    intake_task,\n",
        "    science_analysis_task,\n",
        "    formatting_task\n",
        "]\n",
        "\n",
        "# --- Crew Instantiation ---\n",
        "# Create the Crew instance. It will manage the sequential execution of tasks using the defined agents.\n",
        "# The LLM logic is now handled by the individual agents as configured in Cell 5.\n",
        "print(\"--- Instantiating Crew (Relying on LLM assigned to individual agents) ---\")\n",
        "science_department_crew = Crew(\n",
        "    agents=all_agents,\n",
        "    tasks=crew_tasks,\n",
        "    process=Process.sequential, # Tasks will run in the order defined in 'crew_tasks'.\n",
        "    # llm= or llm_config= are omitted here; using agent-specific LLMs.\n",
        "    verbose=True, # Enable logging of Crew and Agent actions. Set to False to reduce output.\n",
        "    # memory=True, # Optional: Uncomment to enable memory across tasks/runs.\n",
        "    # cache=True, # Optional: Uncomment to cache task results.\n",
        ")\n",
        "\n",
        "# --- Confirmation ---\n",
        "print(\"--- Crew Created (Relying on Agent-Specific LLMs) ---\")"
      ],
      "metadata": {
        "id": "08U61yIjCOcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Kickoff the Simulation (No Direct LLM Test)\n",
        "# Starts the Crew execution process with the user's input.\n",
        "# Includes error handling for potential issues during the run.\n",
        "# RUN THIS CELL AFTER RESTARTING THE RUNTIME and running Cells 2-7\n",
        "\n",
        "print(\"\\n--- Science Query Solving Mode Initializing ---\")\n",
        "print(\"Please provide the topic and your initial question/prompt.\")\n",
        "\n",
        "# --- Get User Input ---\n",
        "try:\n",
        "    user_topic = input(\"Enter the topic: \")\n",
        "    user_prompt = input(\"Enter your question or prompt: \")\n",
        "except EOFError:\n",
        "    # Handles cases where input might fail (e.g., non-interactive environment)\n",
        "    print(\"\\nWarning: Input stream closed unexpectedly. Using default values for demonstration.\")\n",
        "    user_topic = \"General Relativity\"\n",
        "    user_prompt = \"Explain the basic concept of spacetime curvature simply.\"\n",
        "\n",
        "# Bundle inputs into a dictionary for the kickoff method.\n",
        "# Keys must match placeholders '{user_topic}' and '{user_prompt}' in the intake_task description.\n",
        "inputs = {\n",
        "    'user_topic': user_topic,\n",
        "    'user_prompt': user_prompt\n",
        "}\n",
        "\n",
        "print(f\"\\n--- Inputs Received ---\\nTopic: {user_topic}\\nPrompt: {user_prompt}\")\n",
        "print(\"\\n--- Starting Simulation... ---\")\n",
        "print(\"Note: Verbose output from the Crew and Agents will follow.\")\n",
        "\n",
        "# --- Crew Execution ---\n",
        "# Verify necessary components (LLM object for agents, tool) were initialized in Cell 4.\n",
        "# The Crew itself relies on the LLM assigned to agents in Cell 5.\n",
        "if 'llm' in globals() and llm is not None and 'web_scraper_tool' in globals() and web_scraper_tool is not None:\n",
        "    try:\n",
        "        print(\"\\nAttempting crew.kickoff()...\")\n",
        "        # Start the main execution flow.\n",
        "        result = science_department_crew.kickoff(inputs=inputs)\n",
        "\n",
        "        # If kickoff completes without throwing an exception:\n",
        "        print(\"\\n\\n--- Simulation Complete ---\")\n",
        "        print(\"\\n--- Final Formatted Output ---\")\n",
        "        # Print the final result produced by the last task (formatting_task).\n",
        "        print(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any error during the crew's execution.\n",
        "        print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "        print(\"🚨🚨🚨 Crew Execution Failed During Kickoff! 🚨🚨🚨\")\n",
        "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "        print(f\"\\nError Type: {type(e).__name__}\")\n",
        "        print(f\"Error Details: {e}\")\n",
        "        # Displaying the traceback helps pinpoint where in the process the error occurred.\n",
        "        print(\"\\n--- Full Traceback (Crew Kickoff) ---\")\n",
        "        traceback.print_exc()\n",
        "        print(\"--- End Traceback (Crew Kickoff) ---\")\n",
        "        print(\"\\n--- Troubleshooting Hints ---\")\n",
        "        print(\" * Review the traceback above for specific error location.\")\n",
        "        print(\" * Check the verbose agent output preceding the error for context.\")\n",
        "        print(f\" * If '503 Service Unavailable', Google's servers for model '{selected_model}' might be overloaded. Wait and retry Cell 8.\")\n",
        "        print(\" * Ensure API keys (Cell 2) are correct, active, and billed if necessary.\")\n",
        "        print(\" * Ensure model name in Cell 4 is correct and available.\")\n",
        "\n",
        "else:\n",
        "    # This message indicates a setup failure in earlier cells.\n",
        "    print(\"\\n🚨 Cannot start simulation because critical components (LLM or Web Scraper) failed to initialize.\")\n",
        "    print(\"🚨 Please review the output from Cell 4 for initialization errors and fix them first.\")\n",
        "\n",
        "print(\"\\n--- End of Program ---\")"
      ],
      "metadata": {
        "id": "WrzkRws3CQai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}